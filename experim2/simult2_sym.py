import dataclasses
import math
import numpy as np
from scipy.interpolate import interp1d

# from typing import ...
from operator import xor


"""
    Simulates the example 1 of [1].
    [1]. Smith and Brown 2003. "Estimating a State-Space Model from Point Process Observations".
"""

# -------------------------------
# * epxeriment
#    * simulation
#       * simulation inputs
#       * simulation results
# -------------------------------

"""
Symbols legend:

    _Î : numpy arrays of 1 dim
    _ÎÎ : numpy arrays of 2 dims
    _Î¾  : list, or variable length

    _ğ‘´  : trials. Indexed by trial number.

    _Î[neuron_id] : any array that is indexed by [neuron_id]
    _Î[inp_id] : .... input_id

    ÏŸ : any array that is indexed by spike number (spike times, Î› at timepoints) will be suffix-ed by ÏŸ for clarity.
    ÏŸ : Sometimes this is read as "spike". Also point (time-point) or moment in a point process (discrete-indexes list or array)

    xâ‚– : scalar
    [â‚–] : Any subscript []â‚– is a scalar value or element (not the array). It can be wrapped in an array. eg xâ‚–_Î

    Ná¶œ, Î›, Î”: Î» : As used in the Mathematical notation in standard of formulation of Point Process, etc
    [â±â¿áµ›] Î›â±â¿áµ› : Any (inverse) function

    The idea of using unicodes for readability of indices, etc is mine. It is really helps in readbiltiy.
"""

# simargs1: SimulatorArgs1
#         ( .Delta )
# simulation_result

# na
# get_neuron_tau

# DELTA0  ??



MSEC = 1. / 1000.


# **********************************************************************************
# *                                  neuron model
# **********************************************************************************


"""
A neurons is characterised by equations 2.2 and 2.6, as in example 1 of [1].
Ref. equations #Eq.1 and #Eq.2
"""


class Neuron_static:
    def report_neuron(n, Delta):
        tau = Neuron_static.get_neuron_tau(n, Delta)
        print('Tau=', tau * 1000.0, ' (msec)')
        print('Noisiness:  sigma_eps = ',
            n['sigma_eps'] * 1000.0, ' (milli Volts per sample)')


    def get_neuron_tau(n, Delta):
        # todo: def get_ER_tau(n, Delta, rho)  # ER: Exponential Relaxation
        tau = - Delta / math.log(n['rho'])
        return tau


    def get_neuron_rho(tau, Delta):
        rho = math.exp(- Delta / tau)
        return rho

    def n0_prot():
        CORRECT_IT = 1.0

        n0 = {
            # Latent process model
            'rho': 0.99,
            'alpha': 3.0,
            'sigma_eps': math.sqrt(0.001),  # noisiness

            # Latent-to-observable (gain), or, state-to-Lprobability
            'mu': -4.9 + CORRECT_IT*math.log(1000),
            'beta': 0.0
        }
        print(repr(n0))
        return n0

        # see describe_model_latex()


        descriptions = {
            'rho': ["", ""],
            'alpha': ["input gain", "volts per amps"],
            'sigma_eps': ["noisiness: noise amplitude", ""],

            'mu': ["", ""],
            'beta': ["", ""]
        }

# Part of the problem specs, but not the Delta used in the simulation.
DELTA0 = 1.0 * MSEC

# **********************************************************************************
# *                                  simulation
# **********************************************************************************

#simargs1  # simulation args
#simargs1.K
# simulator.K

class SimulatorArgs1(object):
    """
       `.T` Simulation duration (Time length) (all time units in seconds)
       `.K` length (bins/timesteps/intervals): int
       `.Delta`: (seconds)

       invariants:
            duration ~= K * Delta

    """
    # old incorrect comment: Simulation Time Length (Intervals)


    Delta: float
    K: int
    T: float

    def __init__(self, _K=None, duration=None, _deltaT=None):
        """
            Either based on `_K` or `duration`
            They specify the duration of simulation.
        """
        #self.Delta = 0.000
        #self.K = -1
        #self.T = 0.0000
        assert _deltaT is not None, '_deltaT: time-step (bin) size in seconds'

        if _K is not None:
            assert duration is None
            self.K = _K
            #self.Delta = self.T / float(self.K)
            #self.Delta = 1 * MSEC
            self.Delta = _deltaT
            self.T = self.K * self.Delta

            """
            elif duration is not None:
                # self.K = 3000
                # self.T = 3.0; self.Delta =  # sec
                self.T = duration
                self.Delta = 1 * MSEC  * 0.01
                self.K = int(self.T / self.Delta + 1 - 0.00001)
                print( "K=", self.K )
            """
        elif duration is not None:
            assert _K is None
            self.T = duration
            #self.Delta = 1 * MSEC * 0.2
            self.Delta = _deltaT
            self.K = int(self.T / self.Delta + 1 - 0.00001)

        else:
            assert False, "Either `_K` or `duration` needs be specified"

        print("Simulation time-steps: K=%g" % self.K)

    def invar(self):
        # simargs1.K = 3000
        # simargs1.T = 3.0; simargs1.Delta =  # sec
        # simargs1.K = int(simargs1.T / simargs1.Delta + 1)

        assert simargs1.K
        assert simargs1.Delta
        assert simargs1.T

    # produces each timestep? no longer.
    # simulate_input()
    # provides: 1. basic simulatin args (part 1), instantiates simargs1
    # also user-interface for that. Conventient providing of three items: K/dt/T
    # Could be a factory method as part of SimulatorArgs1!
    def simargs_factory(_K=None, duration=None, deltaT=None):

        assert xor(_K is None, duration is None), \
            """ Simulation duration is either based on `_K` or `duration`.
                duration ~= K * Delta
            """
        # todo: remove global
        global simargs1
        # simargs1.T = Simulation Time Length (Sec)
        assert deltaT is not None, 'deltaT: time-step (bin) size in seconds'
        simargs1 = SimulatorArgs1(_K=_K, duration=duration, _deltaT=deltaT)
        return simargs1


# old idea, occluded by the idea of `simulate_step()`:
# ... = simulate_input()



def input_Iâ‚–(recurrent_state, aux_input):
    (last_every_second,) = recurrent_state
    (t, Î”t,) = aux_input
    isfirst = last_every_second is None

    if isfirst:
        last_every_second = -float('inf')

    every_second = (t) % 1.0
    fire = every_second < last_every_second
    if fire:
        Iâ‚– = 1.0
    else:
        Iâ‚– = 0.0

    # What is this? Is it Dirac? If so, why not multiplied by 1/Delta?
    last_every_second = every_second

    output, recurrent_state, aux_input = (Iâ‚–,), (last_every_second,), (t,)
    return output, recurrent_state, aux_input

class InputDriver_static:
    # produces each timestep
    # the idea was it actually provided the INPUT signal! (Iâ‚–)
    # input also drives the program flow !
    def simulate_input_and_drive_next_step(simargs1):

        last_every_second = None
        for k in range(simargs1.K):
            t = k * simargs1.Delta
            (Iâ‚–,), (last_every_second,), (t,) = input_Iâ‚–((last_every_second,), (t, simargs1.Delta,))
            yield k, t, [Iâ‚–,]


# comprised of multiple neurons
class FullModel:

    def __init__(self) -> None:
        """
        Generates an instance
        """

        BETA_RANGE = [0.9, 1.1]
        NEURONS = 20

        na = []
        for i in range(NEURONS):
            n = Neuron_static.n0_prot().copy()
            d = BETA_RANGE[1] - BETA_RANGE[0]
            n['beta'] = 1.1  # (np.random.rand() * d) + BETA_RANGE[0]
            na.append(n)

        self.na = na


# local loop-updating variables
# last_xâ‚– = 0.0
# Nc = 0


# `deltaT` was:
#     1 * MSEC * 0.2 (when duration is specified)
#     1 * MSEC (when K is specified)
simargs1 = SimulatorArgs1.simargs_factory(duration=3.0, deltaT=1 * MSEC * 0.2)

simargs1.invar()

full_model = FullModel()

# Slow, hence, cache!
# neuron instance
class Neuron:
    def init_slow_cache(self, n_obj):
        _tau = Neuron_static.get_neuron_tau(n_obj, DELTA0)
        _rho_corrected = Neuron_static.get_neuron_rho(_tau, simargs1.Delta)
        _sigma_eps_corrected = full_model.na[0]['sigma_eps'] * \
            math.sqrt(simargs1.Delta/DELTA0)
        print("_rho_corrected = ", _rho_corrected, "rho=", full_model.na[0]['rho'])
        print("_sigma_eps_corrected = ", _sigma_eps_corrected,
                "sigma_eps=", full_model.na[0]['sigma_eps'])

        self._sigma_eps_corrected = _sigma_eps_corrected
        self._rho_corrected = _rho_corrected

def new_list_1d(size1):
    return [None] * size1

def new_list_2d(size1, size2):
    # rows x columns
    out = []
    for i1 in range(size1):
        row = []
        for i2 in range(size2):
            row.append(None)
        out.append(row)
        assert len(row) == size2
    assert len(out) == size1
    return out

# [neuron_id]
NEURONS_NUM = 1
TRIALS_NUM = 10
if True:
    tÎ = np.full((simargs1.K,), np.nan)

    x_ÎÎ = np.full((NEURONS_NUM, simargs1.K,), np.nan)
    xlogpr_ÎÎ = np.full((NEURONS_NUM, simargs1.K,), np.nan)
    Ná¶œ_ÎÎ = np.full((NEURONS_NUM, simargs1.K,), 99999, dtype=int)
    fire_probabilityÎÎ = np.full((NEURONS_NUM, simargs1.K,), np.nan)
    Î»_ÎÎ = np.full((NEURONS_NUM, simargs1.K,), np.nan, dtype=float)
    Iâ‚–_ÎÎ = np.full((NEURONS_NUM, simargs1.K,), np.nan)

    # output.
    # Non-square. Hence, list of nparrays
    # ÏŸ_timesÏŸ_Î = new_list_1d(NEURONS_NUM)
    ÏŸ_timesÏŸ_ğ‘´ Î = new_list_2d(NEURONS_NUM, TRIALS_NUM)

    # Î›_at_spikes_Î = new_list_1d(NEURONS_NUM)
    Î›_at_spikes_ğ‘´ Î = new_list_2d(NEURONS_NUM, TRIALS_NUM)

    # local loop-updating variable(s) / the recurrent state
    Ná¶œ_Î¾ = np.zeros((NEURONS_NUM,))
    last_xâ‚–_Î¾ = np.zeros((NEURONS_NUM,))
    # last_xâ‚– = 0.0
    # Nc = 0

    # for neuron_id in range(1):
    neuron_id = 0
    neur_instance = [Neuron()]
    neur_instance[neuron_id].init_slow_cache(full_model.na[neuron_id])

for k, t, Iâ‚–_Î in InputDriver_static.simulate_input_and_drive_next_step(simargs1):

    # the recurrent state: (last_xâ‚–_Î¾, Ná¶œ_Î¾,)
    # aka. the local loop-updating variables


    # print( t, k, Iâ‚–_Î )

    neuron_id = 0
    n = full_model.na[neuron_id]

    is_first_step = (k == 0)

    # def STEP(..., is_first_step)


    # *************************
    # *  Neuron model
    # *************************
    if False:
        # xâ‚– is the State
        epsâ‚– = n['sigma_eps'] * np.random.randn()

        # dirac_factor = 7.0  # terrible. Why no refactory period?
        dirac_factor = 1.0

        #dirac_factor = 1.0 / simargs1.Delta
        # print( "dirac_factor,",dirac_factor )
        xâ‚– = n['rho'] * last_xâ‚–_Î¾[neuron_id] + n['alpha'] * \
            Iâ‚–_Î[inp_id] * dirac_factor + epsâ‚–  # Eq.1

    inp_id = 0
    if True:
        dirac_factor = 1.0
        epsâ‚– = neur_instance[neuron_id]._sigma_eps_corrected * np.random.randn()
        xâ‚– = neur_instance[neuron_id]._rho_corrected * last_xâ‚–_Î¾[neuron_id] + \
            n['alpha'] * Iâ‚–_Î[inp_id] * dirac_factor + epsâ‚–  # Eq.1

    # last_xâ‚–_Î¾ should be outside a loop function
    # last_xâ‚– = xâ‚–
    last_xâ‚–_Î¾[neuron_id] = xâ‚–

    # xlp is x at ?
    xlp = n['mu'] + n['beta'] * xâ‚–
    Î»â‚– = math.exp(xlp)  # Eq.2
    # What will guarantee that xlp < 0 ? i.e. probability < 1
    # Where is x reset?

    # *****************************
    # * Point process simulation
    # *****************************

    fire_probability = Î»â‚– * simargs1.Delta  # * 100
    fire = fire_probability > np.random.rand()

    #output = (xâ‚– * simargs1.Delta) > np.random.rand()
    #Nc += output

    # total count
    Ná¶œ_Î¾[neuron_id] += fire

    # set all (xâ‚–, Nc, xlp),
    # not: ?( t, Iâ‚–)
    # t_arr:
    tÎ[k] = t

    x_ÎÎ[neuron_id][k] = xâ‚–
    Ná¶œ_ÎÎ[neuron_id][k] = Ná¶œ_Î¾[neuron_id]
    Iâ‚–_ÎÎ[inp_id][k] = Iâ‚–_Î[inp_id]
    del xâ‚–, Iâ‚–_Î

    xlogpr_ÎÎ[neuron_id][k] = xlp
    del xlp

    fire_probabilityÎÎ[neuron_id][k] = fire_probability
    Î»_ÎÎ[neuron_id][k] = Î»â‚–

    if is_first_step:
        Neuron_static.report_neuron(n, simargs1.Delta)

    # del x_arr,     xlogpr_arr,    Nc_arr,    fire_probability_arr,    Î»_arr,    I_arr,
    del Î»â‚–, fire_probability, t, fire

    # keep the recurrent state: (aka. the local loop-updating variables)
    # del last_xâ‚–_Î¾, Ná¶œ_Î¾

print("Simulation time = T =", simargs1.T, ". Mean rate = ",
      Ná¶œ_ÎÎ[:][-1].astype(float)/simargs1.T, "(spikes/sec)")

for neuron_id in range(1):
    print("Integral of Î» = ", np.sum(Î»_ÎÎ[neuron_id]) * simargs1.Delta)
    print("Mean Î» = ", np.sum(Î»_ÎÎ[neuron_id]) * simargs1.Delta / simargs1.T)


def cumsum0(x, startv=0.0,  cutlast=True):
    """
        Numerical integration.
        generates a cumsum that starts with 0.0,
        of the same size as x
        To maintain the size, it removes the last element,
        and returns it separately.
        """
    c = np.cumsum(x)
    maxval = c[-1]
    c = np.concatenate((np.array([startv]), c))
    if cutlast:
        c = c[:-1]

    return c, maxval


def generate_Î›_samples_unit_exp1(total_rate):
    """
    Generates samples from
    Exponential distribution
    Î» = 1.0

    PDF(x) = Î» exp(-Î»x)

    Name evolution: Old names:
        generate_unit_isi
        generate_isi_samples_unit_exp1
        generate_Î›_samples_unit_exp1

    where x = ISI in temrs of "virtual-time" (Î›)
    (Not really ISI: but ISI-Î› )

    Enough number of samples to fit the whole `total_rate` (Î›)

    `total_rate` units are in "virtual-time" (rate, Î», intensity-integrated, capital Lambda: Î› )
    ISIÎ›: Inter-spike inter-val -> inter-Î›-val
    interval implies physical "time". But this is virtual-time (Î›)

    True-time (internal, canonical, natural!)

    ISI = TR(R)

    time_quantiles01 -> Î›_quantiles
    By q01 I meant the ISI in terms of this.
    Max of sum(q01) is Sum(Î») = (disrete)Sum(Î›) = Î›
    Evolution:
        Sum(Î») = Î›
        (disrete)Sum(Î») = Î›
        Sum(Î») = (disrete)Sum(Î›) = Î›
        âˆ«Î» = (disrete)Sum(Î”Î›) = Î›
        âˆ«Î» = Î£(Î”Î›) = Î›
        âˆ«Î» dt = Î£(Î”Î›) = Î›

    But here:
        Î› = Î£ (isi?)
        Î› = Î£(Î”Î›)

        isi? = Î”Î›
    On the other hands, the units of Î» are 1/time?

    No, in fact, the time is added to it by the integration:
        âˆ«Î» dt  is unit-less
        Hence, Î» is 1/t or better to say: 1/Î”t?
    I am adding back:
        1. physical Dim
        2. Î” or whole (Î£). Î£Î” = whole. Î£Î” = id
            Î” = Î£^{-1} * id ?!
            Î” = 1/Î£ * id
            Î” = id/Î£ (but in opposite order)

        3. Adding back the natures other than time. e.g. Î›-ness.

        4. Maybe: DIM of `rand()`. (?)

        5. log-ness as DIM. log-ness is important.
            log-transforms changre DIM. (BEcause they are in sa differnt space!)

            Î£,Î” are kind of transformations:    the results are relative/absolute (to reference points).
            jens (material) is different.
            This is a very fundamental quality.

            Î£ ( seq1 ) = cusum
            Î” (seq2) = diff
            Î£(Î”) is obviously are transfomrations.

        6. Nature of space (of transformation)
            eg rand is in its own "space".


    The `rand()` itself has some DIM (?)

    The idea is to keep track of the dimentionality, so that you dont need to remember what transformations are done inside.
    So the output "type" is about interface: to avoid the inside.
    But to give sufficient info about inside.

    The language of input/output needs "type".

    So what is the type of output here?

    Î£
    (
        desribe type in terms of the transfomrations. a "composition" of them.
        A composition is an architecture. I the shape of the circuit.
        DIMension is about the general shape of ciruit - in that sense.
        A homeomorphism of the circuit itself?
        The black box has in its outputs a homemorphism of inside?
        (But hiding certain aspects of inside. Not all)
    )
    Î£(x)
    Î£(Î”)
    Î£(x = Î”(.)) =  // not to be confuse with a function x=>
    Î£(x = (Î”=(âˆ«Î» dt))) =
    Î£(Î”=(âˆ«Î» dt))
    // ^ This also confirms that what is inside the Î£ is a Î”. Hence, we end of having a Î£(Î”) or Î£Î”.
    Î£(Î”: âˆ«Î» dt)
    Î£(Î”: âˆ«Î» dt st. input = Î”)
    By input I mean rand !
    But "Î£(Î”: âˆ«Î» dt)" is the charactger ofd the type.
        It is a whole picture. And you mark the inpt and output there.
    "output" Î£("input" Î”: âˆ«Î» dt)
    Then attach: (Occam: IO language: a? a!)
    "input"! = `rand()`   # attach
    Occam language:
    "output!" Î£("input?" Î”: âˆ«Î» dt)
    In fact !? already sa it is output or input. ut we still use "" (verbal) labels.
    "output!" Î£("input?" Î”: âˆ«Î» dt)

    "output"! Î£("input"? Î”: âˆ«Î» dt)  "input"! `rand`
    "output"! Î£("input"? Î”: âˆ«Î» dt)  "input"!: `rand`
    *  "input"!: `rand` <---- simlar pattern to: (Î”: ...)
    *  `rand` "input"!  <--- input outputs the previous expression
    label, after or before?
    "After-" notation:
        Î£("input"? Î”: âˆ«Î» dt) "output"! ;  `rand` "input"!
        Î£("input"? Î”: âˆ«Î» dt) -> "output"! ;  `rand` -> "input"!

    "After-" notation: for bother direcitons of input/output?
        Î£("input"? <- Î”: âˆ«Î» dt) -> "output"! ;  `rand` -> "input"!
        Î£("input"? -> Î”: âˆ«Î» dt) -> "output"! ;  `rand` -> "input"!

        (Î£( Î”: âˆ«Î» dt) -> "output"! , "input"? ->Î”) ;  `rand` -> "input"!

    Full picture:
        Î£( Î”: âˆ«Î» dt)
        Î£( Î”: (âˆ«Î» dt) = "input": `rand`)
        Î£( Î”? (âˆ«Î» dt) = input? `rand`)
        Î£( Î”?! (âˆ«Î» dt) = input?! = `rand`)
        Î£( (âˆ«Î» dt)  =  Î”?! = input?! = `rand`)
        Î£( Î”?!  = (âˆ«Î» dt) = input?! = `rand`)

    How time is eliminated?
            Î£( Î”?!  = (âˆ« (Î»?) dt) = input?! = `rand`)
    Î»? ---> Î» is not geivern here
    :  -----> as
    =  -----> as
    ?!  -----> as, attached immediately.

    Î£( Î”  = (âˆ« (Î»= 1/ISI) dt) = input = `rand`)
    not sure about ISI here
    Where is ISI? In fact:
    ISI is closely related to Î”.
    ISI = time-quantile (Î”)?
    NO, we need the map of almbda.
    Yes we do have it.

    time = inv(Î›(Â·))

    I didn't utilise âˆ˜ !

    Î£ âˆ˜ Î” = (âˆ«dt) âˆ˜ (Î»(Â·)?),  ... = `rand` := input
    aha:
    Î£ âˆ˜ (Î” = (âˆ«dt) âˆ˜ (Î»(Â·)?)),  ... = `rand` = input
    âˆ˜ means apply.
    Î£ âˆ˜ (Î” = (âˆ«dt) âˆ˜ (Î»?âˆ˜(Â·)))

    Î£ âˆ˜ (Î” := (âˆ«dt) âˆ˜ (Î»?âˆ˜(Â·)))

    Now the meaning of / correct name of this function is clear
    instead of ISI, we should say, Î›
    Î›_quantiles = generate_Î›_samples_unit_exp1(maxÎ›)
    was: Î›_quantiles = generate_isi_samples_unit_exp1(maxÎ›)
    was: time_quantiles = generate_isi_samples_unit_exp1(maxÎ›)
    was: quantiles01 = generate_unit_isi(maxv)

    simply from a mythtake:! st += isi
    Important:
        isi <-> Î”Î›

    """
    """
    st -> sÎ›
    sÎ› = sumÎ› = Î›

    quantiles01 <-> Î›
    aks: time_quantiles01 (which is totally wrong!)

    Correspondance: Î›quantiles <-> spike_timesÏŸ

    spike_times_Al -> ÏŸ_times_Î¾ -> ÏŸ_times_Î -> ÏŸ_timesÎ¾_Î? -> ÏŸ_timesÏŸ_Î (good: ÏŸ indicates some kind of array suffix (redunndancy in the name that specifies the type)). Also it is not soft (list)

    Î›_at_spikes_Al -> Î›ÏŸ_Î¾ -> Î›_atÏŸ_Î¾  -> Î›_at_spikes_Î¾ -> Î›_at_spikes_Î

    Î›_quantiles -> Î›_atÏŸ ->? Î›_at_spikes

    t_arr -> tÎ  (should I use t_Î instead?)
    """
    # print( "ISI(%g):"%(total_rate), end='')
    Î› = 0.0
    Î›a = []
    while Î› < total_rate:
        if Î› > 0.0:
            Î›a.append(Î›)
        Î”Î› = -math.log(np.random.rand())
        # print( Î”Î›, Î›a, end='')
        # Î›a.append(Î”Î›)
        Î› += Î”Î›
        # if Î› > total_rate:
        #    break
    # print()
    return np.array(Î›a)

# Î»_arr is already small. -> Î»_Î

# Generates a Point Process

def generates_time_points(Î»_Î, Î”T, tÎ):
    # tÎ
    #Î›cumintegrÎ»_Î, maxÎ› = cumsum0(Î»_ÎÎ[neuron_id], cutlast=False)*simargs1.Delta
    #t_arr_aug = np.concatenate(tÎ, np.array([tÎ[-1]+simargs1.Delta]))
    #Î›cumintegrÎ»_Î, _ = cumsum0(Î»_ÎÎ[neuron_id], cutlast=True)*simargs1.Delta
    cumintegrÎ»_ÎÎ¾2, _ignore_max = cumsum0(Î»_Î, startv=0.0, cutlast=True)
    Î›cumintegrÎ»_Î = cumintegrÎ»_ÎÎ¾2 * Î”T
    # Î›cumintegrÎ»_Î = Î›(t) = Î›t   Î›t_arr
    # todo: find a unicode substitute for `_arr` suffix.

    maxÎ› = Î›cumintegrÎ»_Î[-1]
    assert Î›cumintegrÎ»_Î[-1] == np.max(Î›cumintegrÎ»_Î), "monotonically increaseing"

    # time_reversal_transform

    # Time-Rescaling: Quantile ~ (physical) time (of spikes)
    # todo: rename Î›_quantiles
    # Î›_quantiles is ...
    # Converts Î› -> time. time(Î›)
    time_rescaling_interp_func = interp1d(Î›cumintegrÎ»_Î, tÎ, kind='linear')
    Î›â±â¿áµ› = time_rescaling_interp_func
    # (x,y, ...)  y = F(x).  tÎ = F(Î›cumintegrÎ»_Î)
    # time_rescaling_interp_func: Î› -> t
    # Hence, the opposiute of Î›(t)
    # t(Î›)  tÎ›
    # => `time_rescaling_interp_func` IS the Time-Rescaling transformation function
    # It is a continuous function
    # It is in fact better called Î›_rescaling
    #     But its standard Mathematical name is Î›_rescaling
    #     It is about Time-rescaling "Theorem"
    # Converts Î› -> time. time(Î›)
    # In a sense, rescaling means calculating "quantile"s. Hence the name: Î›quantiles (spike_timesÏŸ), spike_Î›s
    #    Î›quantiles, spike_Î›s, Î›_at_spikes, Î›_at_points, Î›_points (time_points)
    #   time_of_spikes, Î›_of_spikes
    # Î›quantiles -> Î›_at_spikes
    # However, note that it is about uotput spikes

    # Time-rescaled quantiles:
    #Î›_quantiles = np.arange(0,maxÎ›,maxÎ›/10.0 * 10000)
    Î›_atÏŸ = generate_Î›_samples_unit_exp1(maxÎ›)
    # print( Î›_atÏŸ )

    # empty_spikes, empty_spiketrain, no_spikes
    no_spikes = Î›_atÏŸ.shape[0] == 0
    assert no_spikes or \
        np.max(Î›cumintegrÎ»_Î) >= np.max(Î›_atÏŸ)
    assert no_spikes or \
        np.min(Î›cumintegrÎ»_Î) <= np.min(Î›_atÏŸ)
    if no_spikes:
        print("Warning: empty spike train. *****")

    spike_timesÏŸ = time_rescaling_interp_func(Î›_atÏŸ)
    spike_timesÏŸ = Î›â±â¿áµ›(Î›_atÏŸ)
    # why changed to this?
    #spike_timesÏŸ = time_rescaling_interp_func(Î›cumintegrÎ»_Î)

    del maxÎ›, Î›cumintegrÎ»_Î
    # del spike_timesÏŸ, Î›_atÏŸ
    assert spike_timesÏŸ.shape == Î›_atÏŸ.shape
    return Î›_atÏŸ, spike_timesÏŸ


for trial in range(TRIALS_NUM):
    # Î›_quantiles
    Î›_atÏŸ, spike_timesÏŸ = \
        generates_time_points(Î»_ÎÎ[neuron_id], simargs1.Delta, tÎ)

    # based on stackoverflow.com/questions/19956388/scipy-interp1d-and-matlab-interp1
    # spikes = (spike_timesÏŸ, Î›_atÏŸ)  # spikes and their accumulated Î›

    # ÏŸ_times_Î <- ÏŸ_times_Î¾ = spike_times_Al
    ÏŸ_timesÏŸ_ğ‘´ Î[neuron_id][trial] = spike_timesÏŸ
    # Î›_at_spikes_Î¾ = Î›_atÏŸ_Î¾ = Î›ÏŸ_Î¾ = Î›_at_spikes_Al
    Î›_at_spikes_ğ‘´ Î[neuron_id][trial] = Î›_atÏŸ
    del spike_timesÏŸ, Î›_atÏŸ

    # todo: (Î›_at_spikes_Î¾) Î›_at_spikes_Î -> Î›_atÏŸÎ¾ ? or Î›_atÏŸ_Î¾ ?  or Î›ÏŸ_Î¾ ?
    assert len(ÏŸ_timesÏŸ_ğ‘´ Î) == len(Î›_at_spikes_ğ‘´ Î), "number of neurons (PP channels) should match"
    assert len(ÏŸ_timesÏŸ_ğ‘´ Î[neuron_id]) == len(Î›_at_spikes_ğ‘´ Î[neuron_id]), "number of trials should match"
    # remove this line later:
    #print( ÏŸ_timesÏŸ_ğ‘´ Î[neuron_id][trial].shape , Î›_at_spikes_ğ‘´ Î[neuron_id][trial].shape )
    assert ÏŸ_timesÏŸ_ğ‘´ Î[neuron_id][trial].shape == Î›_at_spikes_ğ‘´ Î[neuron_id][trial].shape

simulation_result = \
    (tÎ, x_ÎÎ, xlogpr_ÎÎ, Î»_ÎÎ, ÏŸ_timesÏŸ_ğ‘´ Î, Î›_at_spikes_ğ‘´ Î, fire_probabilityÎÎ, Ná¶œ_ÎÎ, Iâ‚–_ÎÎ)

# import sys
# sys.path.append('/ufs/guido/lib/python')
from sim2_plot import *

plot_all(simargs1, full_model.na, Neuron_static.get_neuron_tau, simulation_result, DELTA0, simargs1.Delta)
